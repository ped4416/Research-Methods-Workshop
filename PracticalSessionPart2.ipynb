{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PracticalSessionPart2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSa8mLq1UK79EM1Q/txI2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ped4416/Research-Methods-Workshop/blob/main/PracticalSessionPart2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaLKnBRcfZ9R"
      },
      "source": [
        "# Research Methods Talk 16th Dec 2020\n",
        "##Introduction to statistics for questionnaires\n",
        "###Practical session Part 2\n",
        "\n",
        "* Taken from Chapter 12 in the **Computer Booklet.pdf** in your resourses folder\n",
        "* Thanks to Mike Griffiths for this content - if you have SPSS you can work through many other excellent **Core Quantitative Methods** in your own time. This booklet summaries many statistical methods that may be useful for your research. \n",
        "\n",
        "First we need to import our data as a .csv file.\n",
        "\n",
        "*   We will use [pandas](https://pandas.pydata.org/) to do this.\n",
        "*   We are using Colab (short for Colaboratory) to access our data and run some statistical tests on that data! \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMDPx8sx8zF"
      },
      "source": [
        "#load our dependencies \n",
        "from google.colab import files\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"pd v = {}\\nnp v = {}\".format(pd.__version__, np.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ym_NQcgI-g"
      },
      "source": [
        "#we will upload from our local drive \n",
        "#run this cell and select the file from your computer...\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLQBwD631FH8"
      },
      "source": [
        "#Introdcution to the data\n",
        "The data file contains the results of an imaginary questionnaire, given to 60 participants.\n",
        "The data file contains the sort of information you might collect from a simple questionnaire:\n",
        "* participant numbers (Part). It is good practice to give each participant a\n",
        "number, and to write the same number on each questionnaire. This\n",
        "allows you to check back to the questionnaire if you need to.\n",
        "* demographic information (Gender and Age)\n",
        "* participants’ responses to six questions (Q1 to Q6). These are related to\n",
        "job satisfaction (e.g. “I like the work I do”). Responses are on a Likert\n",
        "scale running from 1 (strongly disagree) to 7 (strongly agree).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIah6wr2JeT"
      },
      "source": [
        "#now we can load the data into a pd DataFrame to view \n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Questionnaire_Data_v1.csv']))\n",
        "\n",
        "#lets view our data\n",
        "print(df.head(3))\n",
        "print(df.info()) #due to missing data notice \"object\" Dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbfwHq2y4ASy"
      },
      "source": [
        "#Missing data\n",
        "There are a few data points missing. \n",
        "We will ignore these participnats as we want to look at the overall questions in this example. \n",
        "\n",
        "```\n",
        "Use df. dropna() to drop rows with NaN from a Pandas dataframede\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNvIcHrK4gnx"
      },
      "source": [
        "#We have 2 missing values they are empty strings, which Pandas doesn't recognise as null.\n",
        "#let's replace the empty cells with a nan object\n",
        "print(df.shape) #shows 60 rows \n",
        "df.replace(\" \", np.nan, inplace=True) #replace blank values \n",
        "print(df.isnull().sum()) #note that we now have two values Q1 and Q5 that need removing\n",
        "df = df.dropna(axis='rows') #assign our df to remove the null rows \n",
        "df = df.apply(pd.to_numeric) #ensure all data is numeric for analysis \n",
        "print(df.shape) #shows 58 rows\n",
        "print(df.info())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcxSdtPJ5JMF"
      },
      "source": [
        "#print a few basic statistics\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6CZ_5DLISx2"
      },
      "source": [
        "#desciptive stats - how many males vs females are there?\n",
        "#male = 1 female = 2 in this case \n",
        "#calculate count\n",
        "counts = df[\"Gender\"].value_counts()\n",
        "#calculate a basic percentage number\n",
        "percent = df[\"Gender\"].value_counts(normalize=True)\n",
        "#calculate a basic percentage number with % sign \n",
        "percent100 = df[\"Gender\"].value_counts(normalize=True).mul(100).round(1).astype(str) + \"%\"\n",
        "#create a new dataframe to view the data\n",
        "df_gender = pd.DataFrame({\"gender_count\" : counts, \"percentage\" : percent100})\n",
        "print(df_gender)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zHyNOk4190T"
      },
      "source": [
        "#Calculating overall scores on a questionnaire\n",
        "\n",
        "* If the questions constitute a scale, you will need to add up (or average) the\n",
        "answers to different questions. For example, if the questions are all about job satisfaction (as in the example), we might have to add them up to get a total score for job satisfaction. There may be just one total, or sometimes different questions have to be added up to make sub-scales.\n",
        "\n",
        "* If using a published questionnaire, make sure you find the instructions. These may be in a manual or in a journal article. They will give important information on how to calculate the overall score (e.g. whether it is a total or an average, whether there are subscales, whether there are any reverse-scored questions, whether certain questions need to be ignored for any reason). The same source will also tell you who the questionnaire was tested on (the so-called norm group) and what their mean score was; you may wish to compare your own participants’ mean against the norm group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb8L-piW2iXU"
      },
      "source": [
        "#Reverse-scored questions: what they are\n",
        "* We will see how to add up scores in a minute, but first you may have to deal with reverse-scored questions.\n",
        "\n",
        "* If the questions are about how happy people are in their job, a typical question might ask people how much they agree with the statement “I enjoy coming to work.” Obviously the more people agree with this statement, the happier they are in their job. The people who most strongly agree with the statement get the highest score.\n",
        "\n",
        "* However there might be some questions such as “If I could give up work\n",
        "tomorrow, I would.” In this case, the more people agree with the statement, the less they are happy in their job. If the questionnaire has been devised and published by someone else, they should have made it clear if there are any such questions.\n",
        "\n",
        "#Reverse-scored questions: How to deal with them\n",
        "The score needs to be amended so that low scores are changed into high\n",
        "scores, and vice versa.\n",
        "\n",
        "To keep an audit trail and prevent mistakes, it is advisable to keep the old variable as it is and to create a new variable with a new name, such as Q3rev for a reversed version of Q3.\n",
        "\n",
        "The calculation to reverse the questions is actually quite simple: As it is a 7 stage likert scale we can use 8 - Q3 value.\n",
        "\n",
        "* Participant’s score 1 2 3 4 5 6 7 \n",
        "* Reverse score 7 6 5 4 3 2 1 (subtract from 8)\n",
        "* Total of score and reverse score 8 8 8 8 8 8 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iCJGQJdAXdm"
      },
      "source": [
        "#okay now to create a new Q3_rev column and position it next to the origional Q3\n",
        "# Third position would be at index 2, because of zero-indexing.\n",
        "Q3_rev = 8 - df[\"Q3\"]\n",
        "print(type(Q3_rev))\n",
        "df.insert(5, 'Q3_rev', Q3_rev)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf4Y7HmpOx9O"
      },
      "source": [
        "#Add up our scores: ensure you use Q3_rev\n",
        "#create a new pd series summing all 6 questions \n",
        "JobSatTotal = df[\"Q1\"] + df[\"Q2\"] + df[\"Q3_rev\"] + df[\"Q4\"] + df[\"Q5\"] + df[\"Q6\"]\n",
        "\n",
        "#calculate the mean score \n",
        "JobSatMean = JobSatTotal/6\n",
        "\n",
        "#check the scores: \n",
        "#For the example file, the correct first few means are 5.33, 2.33 and 3.50.\n",
        "JobSatMean.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSXhvQahP7Rz"
      },
      "source": [
        "#Checking for problematic questions\n",
        "When you have given your questionnaire to a sample of people, you can check\n",
        "for questions which might cause a problem. There are three ways in which\n",
        "questions might stand out as being problematic. The first two are matters of\n",
        "opinion – their correlations and standard deviations. The third is to look at how they affect Cronbach’s alpha.\n",
        "\n",
        "* Firstly, you can look at the correlations between questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4pNP6hVQJYd"
      },
      "source": [
        "#Pearson product-moment correlation\n",
        "corrQ1_Q2 = stats.pearsonr(df[\"Q1\"], df[\"Q2\"])\n",
        "print('Pearsons: corr and p-value:{}'.format(corrQ1_Q2))\n",
        "corrQ1_Q2, _ = stats.pearsonr(df[\"Q1\"], df[\"Q2\"]) #ignore second value \n",
        "print('Pearsons correlation: %.3f' % corrQ1_Q2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJYWsfgjRiom"
      },
      "source": [
        "* For example, this shows that the correlation coefficient between\n",
        "Q1 and Q2 is .592, that this is highly significant (p < .001).\n",
        "\n",
        "* If one or more of the questions has a particularly low correlation with the others, it suggests that particular question is not getting at the same concept as the other questions. (You might think it is, but perhaps your participants are interpreting the question differently from you.) Read over the question and consider eliminating it from the analysis. Or, if some questions correlate with each other but not with the rest, it may indicate that your questions are tapping into two or more sub-scales, and you might want to consider a factor analysis.\n",
        "\n",
        "* If one of the questions is negatively correlated with the others, it would appear that you forgot to reverse-score it; or that your respondents are interpreting the question very differently from the way you expected. If the latter, you may need to eliminate it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Y26UkXUrhr"
      },
      "source": [
        "Another thing you could consider looking at is the standard deviations. If one of the questions has a much smaller standard deviation than the others, it appears that there is very little difference between participants as to how they answer that question, so perhaps it is not telling you anything. Consider whether it is worth keeping.\n",
        "\n",
        "Of course, if you discard questions for any reason this is an important part of your findings and should be reported in your Results section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmSp49NxU28U"
      },
      "source": [
        "#lets review the standard deviations\n",
        "df_final = df[[\"Q1\",\"Q2\",\"Q3_rev\",\"Q4\",\"Q5\",\"Q6\"]].copy()\n",
        "df_final.describe()\n",
        "#none appear very small so we can consider keeping them all in "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AMdygVVWZPC"
      },
      "source": [
        "#Cronbach’s alpha: how to calculate it\n",
        "Cronbach’s alpha is a measure of how much the questions measure the same\n",
        "thing (i.e. how much the questions as a whole correlate with each other).Again, if you have any reverse-scored questions the reverse-scored questions are the ones to use. \n",
        "\n",
        "We will use a function - see this link for a far more detailed tutorial:\n",
        "https://towardsdatascience.com/cronbachs-alpha-theory-and-application-in-python-d2915dd63586 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5LrnHS-XLKn"
      },
      "source": [
        "#Cronbach’s alpha for Q1, Q2, Q3rev, Q4, Q5 and Q6. \n",
        "#use out df_final with this function: \n",
        "def cronbach_alpha(df):\n",
        "    # 1. Transform the df into a correlation matrix\n",
        "    df_corr = df.corr()\n",
        "    \n",
        "    # 2.1 Calculate N\n",
        "    # The number of variables equals the number of columns in the df\n",
        "    N = df.shape[1]\n",
        "    \n",
        "    # 2.2 Calculate R\n",
        "    # For this, we'll loop through the columns and append every\n",
        "    # relevant correlation to an array calles \"r_s\". Then, we'll\n",
        "    # calculate the mean of \"r_s\"\n",
        "    rs = np.array([])\n",
        "    for i, col in enumerate(df_corr.columns):\n",
        "        sum_ = df_corr[col][i+1:].values\n",
        "        rs = np.append(sum_, rs)\n",
        "    mean_r = np.mean(rs)\n",
        "    \n",
        "   # 3. Use the formula to calculate Cronbach's Alpha \n",
        "    cronbach_alpha = (N * mean_r) / (1 + (N - 1) * mean_r)\n",
        "    return cronbach_alpha\n",
        "\n",
        "\n",
        "cronbach_alpha(df_final) #the result is looking good. See info below. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opf6DmC7YFMk"
      },
      "source": [
        "* There is no hard-and-fast rule on what is an acceptable level for Cronbach’s\n",
        "alpha. Most people would find a figure of above .8 good, and a figure above .7\n",
        "acceptable. Some people (but not everyone) consider that it is possible for alpha to be too high, and say that if it is above .9 then the scale contains too many items that are just the same as each other, and is wasteful53.\n",
        "\n",
        "* If Cronbach’s alpha is too low, you might consider excluding problematic\n",
        "questions (see sections 12.4.1 and 12.4.3). Or it might be appropriate to carry\n",
        "out a factor analysis to create two or more separate scales; each of these is likely to have a higher Cronbach’s alpha than the overall scale.\n",
        "\n",
        "In our case here we have 0.87 so this suggests that the questions are all measuring the same thing for our research. \n",
        "\n",
        "\n",
        "\n",
        "END"
      ]
    }
  ]
}