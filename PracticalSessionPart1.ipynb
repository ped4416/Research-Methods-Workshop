{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PracticalSessionPart1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBfcARFoaXlD83+5Y2vVcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ped4416/Research-Methods-Workshop/blob/main/PracticalSessionPart1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaLKnBRcfZ9R"
      },
      "source": [
        "# Research Methods Talk 16th Dec 2020\n",
        "###Practical session Part 1\n",
        "First we need to import our data as a .csv file.\n",
        "\n",
        "*   We will use [pandas](https://pandas.pydata.org/) to do this.\n",
        "*   We are using Colab (short for Colaboratory) to access our data and run some statistical tests on that data! \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMDPx8sx8zF"
      },
      "source": [
        "#load our dependencies \n",
        "from google.colab import files\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"pd v = {}\\nnp v = {}\".format(pd.__version__, np.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ym_NQcgI-g"
      },
      "source": [
        "#we will upload from our local drive \n",
        "#run this cell and select the file from your computer...\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIah6wr2JeT"
      },
      "source": [
        "#now we can load the cat_dog.csv into a pd DataFrame to view \n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['cat_dog.csv']))\n",
        "\n",
        "#lets view our data\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIvmnwzw_ELY"
      },
      "source": [
        "#remove the Timestamp as it is not really needed now\n",
        "del df['Timestamp']\n",
        "#the column headers are a little long - let's update them\n",
        "df.columns = [\"gender\", \"age\", \"cats\", \"dogs\"]\n",
        "#add an ID number \n",
        "#df.insert(loc=0, column='id', value=np.arange(len(df)))\n",
        "df.insert(loc=0, column='id', value=df.index + 1)\n",
        "\n",
        "#lets view our data again - it should be a bit neater\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcxSdtPJ5JMF"
      },
      "source": [
        "#print a few basic statistics\n",
        "#what variable is missing? \n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dYYHlWf7mKj"
      },
      "source": [
        "#we can also use head and tail to print rows of data out - insert a number argument \n",
        "#this can be useul for larger data sets\n",
        "print(\"df head = \\n{}\\ndf tail = \\n{}\".format(df.head(3), df.tail(3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6CZ_5DLISx2"
      },
      "source": [
        "#desciptive stats - how many males vs females are there?\n",
        "\n",
        "#calculate count\n",
        "counts = df[\"gender\"].value_counts()\n",
        "#calculate a basic percentage number\n",
        "percent = df[\"gender\"].value_counts(normalize=True)\n",
        "#calculate a basic percentage number with % sign \n",
        "percent100 = df[\"gender\"].value_counts(normalize=True).mul(100).round(1).astype(str) + \"%\"\n",
        "#create a new dataframe to view the data\n",
        "df_gender = pd.DataFrame({\"gender_count\" : counts, \"percentage\" : percent100})\n",
        "print(df_gender)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obr6VxAGYHv0"
      },
      "source": [
        "#Run a paired-samples t-test\n",
        "\n",
        "Do we have a prediction based on our sample? \n",
        "Will there be a preference for dogs or cats?\n",
        "\n",
        "Remember we have assumptions... \n",
        "\n",
        "1.   A continuous variable (we assume yes - our preference scores)\n",
        "2.   Two related groups (yes same participants)\n",
        "3.   No significant outliers in the differences between the two related groups ([Test with boxplots - python tutorial](https://statinfer.com/104-3-5-box-plots-and-outlier-dectection-using-python))\n",
        "4.   The distribution of these differences should be approximately normally distributed \n",
        "\n",
        "However, the paired-samples t-test is considered \"robust\" to violations of normality. This means that violations of this assumption can be somewhat tolerated.\n",
        "\n",
        "See [this link](https://statistics.laerd.com/premium/spss/pstt/paired-samples-t-test-in-spss-7.php) for a full description of these assumptions. \n",
        "\n",
        "The hypothesis being tested is:\n",
        "\n",
        "* Null hypothesis (H0): the population mean difference between the paired values is equal to zero\n",
        "* Alternative hypothesis (H1): the population mean difference between the paired values is not equal to zero\n",
        "* If the p-value is less than .05, we can reject the null hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5baPAVtYj-e"
      },
      "source": [
        "#first lets look at some descriptives on our two key variables again\n",
        "#look at the mean value - this should provide a clue\n",
        "df[['dogs','cats']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV7wjhoJeHYB"
      },
      "source": [
        "#Lets look for some outliers... \n",
        "#We need to calculate a differnce score\n",
        "#simply subtract dogs from cats \n",
        "diffs = df['dogs'] - df['cats']\n",
        "print(\"Difference values\\n{}\".format(diffs))\n",
        "%matplotlib inline \n",
        "\n",
        "plt.title(\"diff box plot\")\n",
        "plt.boxplot(diffs)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zyk4ZIKiJXT"
      },
      "source": [
        "#Now to test that the data came from a normal distribution\n",
        "#The Shapiro-Wilk test is recommended if you have small sample sizes (< 50 participants) \n",
        "stats.shapiro(diffs)\n",
        "#The first value is the W test value, and the second value it the p-value.\n",
        "#If the assumption of normality is met the significance level should be more than .05 (i.e., p > .05)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDs1si79jSw-"
      },
      "source": [
        "#Finally lets run the t-test only if we can say all assumtions are met! \n",
        "stats.ttest_rel(df['cats'], df['dogs'])\n",
        "#if the p value < .05 the test is significant \n",
        "#if it is significant and you have many questions you could run further \n",
        "#t-tests to see which questions are driving the effect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nDVr56j6--"
      },
      "source": [
        "#Run a Wilcoxon signed-rank test\n",
        "The Wilcoxon signed-rank test is the non-parametric alternative to the dependent t-test.\n",
        "\n",
        "Do we have a prediction based on our sample? \n",
        "Will there be a preference for dogs or cats?\n",
        "\n",
        "Remember we have assumptions... \n",
        "\n",
        "1.   A continuous variable (we assume yes - our preference scores)\n",
        "2.   Two related groups (yes same participants)\n",
        "3.   The distribution of the differences bwetween groups should be approximately symmetrical in shape\n",
        "\n",
        "\n",
        "See [this link](https://statistics.laerd.com/premium/spss/wsrt/wilcoxon-signed-rank-test-in-spss-3.php) for a full description of these assumptions.\n",
        "\n",
        "The hypothesis being test is:\n",
        "\n",
        "*  Null hypothesis (H0): The difference between the pairs follows a symmetric distribution around zero.\n",
        "* Alternative hypothesis (HA): The difference between the pairs does not follow a symmetric distribution around zero.\n",
        "* If the p-value is less than .05, we can reject the null hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlcLgXpsnh14"
      },
      "source": [
        "#So lets test the assumption that the distribution of the differences bwetween groups is approximately symmetrical in shape\n",
        "#We can use a histogram to test this.\n",
        "#Looking at the histogram you need to make a judgement about whether the distribution is symmetrical. \n",
        "#By visually inspecting the shape of this distribution of difference scores\n",
        "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
        "\n",
        "plt.hist(diffs, bins = 5)\n",
        "plt.title(\"differences - symmetry\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPA8jy9LlEEF"
      },
      "source": [
        "#so lets run the Wilcoxon signed-rank test\n",
        "stats.wilcoxon(df['cats'], df['dogs'])\n",
        "#if the p value < .05 the test is significant \n",
        "#if it is significant and you have many questions you could run further \n",
        "#test to see which questions are driving the effect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdkLdBq0JQ6g"
      },
      "source": [
        "When reporting the results of non-parametric tests it is usual to report medians rather than means. But with Likert scales there is some debate over median vs mean... \n",
        "\n",
        "Consider reporting the mean if you have a normal distribution and potentially median if you have a skewed distribution of your Likert findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mh-zsMHJUxX"
      },
      "source": [
        "#median and mean for our two outcomes\n",
        "mean_dogs = df['dogs'].mean()\n",
        "mean_cats = df['cats'].mean()\n",
        "med_dogs = df['dogs'].median()\n",
        "med_cats = df['cats'].median()\n",
        "\n",
        "#initialise data of lists. \n",
        "data = {'average':['mean', 'median'],\n",
        "        'dogs':[mean_dogs, med_dogs], \n",
        "        'cats':[mean_cats, med_cats]} \n",
        "  \n",
        "#pandas DataFrame of our data\n",
        "df_averages = pd.DataFrame(data)\n",
        "df_averages"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}